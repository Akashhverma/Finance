{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6QVL-_cezgr"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('data.csv',names=['Label', 'Text'], encoding='latin-1')"
      ],
      "metadata": {
        "id": "PMGHTYChulN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic info about the data\n",
        "print(data.head())\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPG2Ek0GvWEE",
        "outputId": "e587aa5a-e6dc-44b1-f5f2-14d7fbe8f4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label                                               Text\n",
            "0   neutral  According to Gran , the company has no plans t...\n",
            "1   neutral  Technopolis plans to develop in stages an area...\n",
            "2  negative  The international electronic industry company ...\n",
            "3  positive  With the new production plant the company woul...\n",
            "4  positive  According to the company 's updated strategy f...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4846 entries, 0 to 4845\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Label   4846 non-null   object\n",
            " 1   Text    4846 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 75.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing functions\n",
        "def get_sequences(texts):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    vocab_length = len(tokenizer.word_index) + 1\n",
        "    max_seq_length = np.max(list(map(len, sequences)))\n",
        "\n",
        "    print(\"Vocabulary length:\", vocab_length)\n",
        "    print(\"Maximum sequence length:\", max_seq_length)\n",
        "\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
        "    return padded_sequences, tokenizer, max_seq_length, vocab_length"
      ],
      "metadata": {
        "id": "cC-OaCbuvWBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_inputs(df):\n",
        "    label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "    df['Label'] = df['Label'].replace(label_mapping)\n",
        "\n",
        "    sequences, tokenizer, max_seq_length, vocab_length = get_sequences(df['Text'])\n",
        "    train_sequences, test_sequences, y_train, y_test = train_test_split(\n",
        "        sequences, df['Label'], train_size=0.7, shuffle=True, random_state=1\n",
        "    )\n",
        "    return train_sequences, test_sequences, y_train, y_test, tokenizer, max_seq_length, vocab_length"
      ],
      "metadata": {
        "id": "lKmGaUcfvV-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "train_sequences, test_sequences, y_train, y_test, tokenizer, max_seq_length, vocab_length = preprocess_inputs(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTTcRQ08vV8J",
        "outputId": "6a85c411-5174-4978-b07f-0c883e91f6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-04e035c88bcd>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['Label'] = df['Label'].replace(label_mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 10123\n",
            "Maximum sequence length: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM-based model\n",
        "def create_lstm_model(input_length, vocab_size):\n",
        "    inputs = tf.keras.Input(shape=(input_length,))\n",
        "    x = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length)(inputs)\n",
        "    x = tf.keras.layers.LSTM(256, return_sequences=False, activation='tanh')(x)\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "NsV800lOvV5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the model\n",
        "model = create_lstm_model(max_seq_length, vocab_length)\n",
        "\n",
        "history = model.fit(\n",
        "    train_sequences,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4js1QjdvV2h",
        "outputId": "14f5ea5e-e456-4ea2-9828-7b795bd93591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5799 - loss: 0.9378 - val_accuracy: 0.5700 - val_loss: 0.9592\n",
            "Epoch 2/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6097 - loss: 0.9066 - val_accuracy: 0.5700 - val_loss: 0.9579\n",
            "Epoch 3/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6040 - loss: 0.9130 - val_accuracy: 0.5700 - val_loss: 0.9671\n",
            "Epoch 4/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6095 - loss: 0.9116 - val_accuracy: 0.5700 - val_loss: 0.9632\n",
            "Epoch 5/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6027 - loss: 0.9246 - val_accuracy: 0.5700 - val_loss: 0.9579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "results = model.evaluate(test_sequences, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {results[0]:.5f}\")\n",
        "print(f\"Test Accuracy: {results[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd6jBAdrvVzr",
        "outputId": "669f43d3-1a49-453d-f06f-bb46c74b12a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.93571\n",
            "Test Accuracy: 58.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## reframe LSTM code to increase accuracy"
      ],
      "metadata": {
        "id": "fVdo5Gbk1ljA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(input_length, vocab_length):\n",
        "    inputs = tf.keras.Input(shape=(input_length,))\n",
        "    x = tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_length,\n",
        "        output_dim=128,\n",
        "        input_length=input_length\n",
        "    )(inputs)\n",
        "    x = tf.keras.layers.LSTM(\n",
        "        256,\n",
        "        return_sequences=True,\n",
        "        activation='tanh'\n",
        "    )(x)\n",
        "    x = tf.keras.layers.Flatten()(x)  # Flattening the outputs\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "gY8bCAs91rPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the LSTM model\n",
        "lstm_model = create_lstm_model(max_seq_length, vocab_length)\n",
        "\n",
        "history = lstm_model.fit(\n",
        "    train_sequences,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj0OTyjO1rNZ",
        "outputId": "96b08caf-f465-4261-9487-f0b3299ad4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5774 - loss: 0.9027 - val_accuracy: 0.6244 - val_loss: 0.8415\n",
            "Epoch 2/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7794 - loss: 0.5250 - val_accuracy: 0.6745 - val_loss: 0.8275\n",
            "Epoch 3/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9429 - loss: 0.1741 - val_accuracy: 0.6863 - val_loss: 1.0620\n",
            "Epoch 4/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9824 - loss: 0.0613 - val_accuracy: 0.6863 - val_loss: 1.0372\n",
            "Epoch 5/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0366 - val_accuracy: 0.6848 - val_loss: 1.3117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = lstm_model.evaluate(test_sequences, y_test, verbose=0)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"LSTM Model Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"LSTM Model Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLZrKndP1rKw",
        "outputId": "b905b9b8-e15f-49ea-b939-c791ad2e6fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Model Test Loss: 0.72925\n",
            "LSTM Model Test Accuracy: 72.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create GRU-based model\n",
        "def create_gru_model(input_length, vocab_length):\n",
        "    inputs = tf.keras.Input(shape=(input_length,))\n",
        "    x = tf.keras.layers.Embedding(input_dim=vocab_length, output_dim=128, input_length=input_length)(inputs)\n",
        "    x = tf.keras.layers.GRU(256, return_sequences=True, activation='tanh')(x)\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "CazBhNeEvVj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the GRU model\n",
        "inputs = tf.keras.Input(shape=(train_sequences.shape[1],))\n",
        "x = tf.keras.layers.Embedding(\n",
        "    input_dim=10123,\n",
        "    output_dim=128,\n",
        "    input_length=train_sequences.shape[1]\n",
        ")(inputs)\n",
        "x = tf.keras.layers.GRU(256, return_sequences=True, activation='tanh')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "gru_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "gru_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = gru_model.fit(\n",
        "    train_sequences,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C72zIHmAvVhK",
        "outputId": "6b4cf9de-a20d-4a72-a3f9-1c16739b798a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6068 - loss: 0.8961 - val_accuracy: 0.6495 - val_loss: 0.8109\n",
            "Epoch 2/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7791 - loss: 0.4914 - val_accuracy: 0.6951 - val_loss: 0.7637\n",
            "Epoch 3/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9549 - loss: 0.1471 - val_accuracy: 0.7054 - val_loss: 0.9028\n",
            "Epoch 4/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0536 - val_accuracy: 0.7099 - val_loss: 1.0840\n",
            "Epoch 5/100\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0168 - val_accuracy: 0.6848 - val_loss: 1.3765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the GRU model\n",
        "results = gru_model.evaluate(test_sequences, y_test, verbose=0)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"GRU Model Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"GRU Model Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnJH3aRQvVP-",
        "outputId": "d279072f-6463-4413-a4cc-f16e9e4291de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU Model Test Loss: 0.64034\n",
            "GRU Model Test Accuracy: 74.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save(\"lstm_model.keras\")"
      ],
      "metadata": {
        "id": "XbBpOCeR4wEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "a7wzvfnL4wBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tokenizer.pkl\", \"wb\") as file:\n",
        "    pickle.dump(tokenizer, file)\n"
      ],
      "metadata": {
        "id": "xgcIIJyw4v_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"lstm_model.keras\")  # or \"lstm_model.h5\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YK5vdfC84v8m",
        "outputId": "68f04354-1271-4982-df60-7e1b4fe7e0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_df3a52c5-4f9b-4e26-bfbe-d25f45d24449\", \"lstm_model.keras\", 20961925)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"tokenizer.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yMja5JYq4v5y",
        "outputId": "6b48e51c-6aa0-4286-ba81-94dc4ea6562d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_342f3844-13a1-4592-aa44-66a281f8eabd\", \"tokenizer.pkl\", 399573)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAh4CGJD4v3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLQN_v8b4v0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yT-9DXaa4vxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwYOdsDW4vuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJVQnmtP4vml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZT64IrBP4vjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM5MfzqJ1ZhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XBmY-PVz1Zeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bc2HP3LL1ZZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9mnLryU1ZWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fu9Qs4zJ1V07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5739rnHc1VyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXqsEJKy1VmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}